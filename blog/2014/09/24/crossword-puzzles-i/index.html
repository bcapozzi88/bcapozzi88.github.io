<!DOCTYPE html>
<html lang="en"
>
<head>
    <title>Crossword Puzzles I: Web Scraping - Brian Capozzi</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="http://bcapozzi88.github.io/blog/2014/09/24/crossword-puzzles-i/">

        <meta name="author" content="Brian Capozzi" />
        <meta name="description" content="Get information about the daily NYT crossword puzzle by using the BeautifulSoup python library in order scrape another blog." />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="http://bcapozzi88.github.io/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="http://bcapozzi88.github.io/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="http://bcapozzi88.github.io/theme/css/pygments/default.css" rel="stylesheet">
    <link rel="stylesheet" href="http://bcapozzi88.github.io/theme/css/style.css" type="text/css"/>

        <link href="http://bcapozzi88.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Brian Capozzi ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="http://bcapozzi88.github.io/" class="navbar-brand">
Brian Capozzi            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="http://bcapozzi88.github.io/pages/about-me.html">
                             About Me
                          </a></li>
                        <li class="active">
                            <a href="http://bcapozzi88.github.io/category/data-posts.html">Data posts</a>
                        </li>
                        <li >
                            <a href="http://bcapozzi88.github.io/category/fun-and-games.html">Fun and games</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
                <li><a href="http://bcapozzi88.github.io/archives.html"><i class="fa fa-th-list"></i><span class="icon-label">Archives</span></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<!--     <div class="container-fluid">
<div class="jumbotron">
    <h1></h1>
    <p></p>
</div>
</div> -->

<div class="container">
    <div class="row">
        <div class="col-sm-9">

    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="http://bcapozzi88.github.io/blog/2014/09/24/crossword-puzzles-i/"
                       rel="bookmark"
                       title="Permalink to Crossword Puzzles I: Web Scraping">
                        Crossword Puzzles I: Web Scraping
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2014-09-24T00:00:00"> Wed 24 September 2014</time>
    </span>



    
</footer><!-- /.post-info -->                    </div>
                </div>
                <hr />
<p>I love crossword puzzles. I do the <a href="http://www.nytimes.com/crosswords/index.html">New York Times crossword puzzle</a> almost every day-- though, I don't actually finish it every day. The puzzle difficulty ramps up as the week progresses, with Monday being the easiest, Saturday being the toughest, and Sunday being a larger puzzle at a Wednesday/Thursday-ish difficulty. Sunday through Thursday puzzles also generally have some sort of theme, while Friday and Saturday puzzles are unthemed. I can usually complete puzzles through Thursday difficulty, occassionally I can finish a Friday puzzle, but I've never even come close to finishing a Saturday.</p>
<p>Rex Parker, the 63rd greatest crossword solver in the universe, has a blog, <a href="http://rexwordpuzzle.blogspot.com">Rex Parker Does the NY Times Crossword Puzzle</a> where he documents each puzzle's constructor and theme, assigns a relative difficulty to the puzzle, and writes his thoughts on the puzzle's fill. I really enjoy reading it, so this seemed like a fun place to get my feet wet learning to web scrape using Python. This was mostly meant to be fun for me, there are a few questions that I thought might be interesting to answer, such as:</p>
<ul>
<li>Who has created the most NYT crosswords?</li>
<li>Do any constructors make particularly hard early-week puzzles or particularly easy late-week puzzles?</li>
<li>Is there a difference in male/female constructors for themed/unthemed puzzles? Rex once commented about there being very few unthemed puzzles created by women, and I wondered how true this was.</li>
<li>Is Rex a grouch? Many commenters seem to think he has negative opinions of most puzzles (I think he's fine).</li>
</ul>
<h2>Web Scraping 101</h2>
<p>Before attempting to answer any of the above questions, we need to actually get some data off of Rex's blog. The home page on the blog looks something like this:</p>
<p><img alt="Rex's Blog" src="/images/Rex_blogshot.png" width="400" height="400"></p>
<p>It displays an image of the the current day's completed crossword puzzle.  There is quite a bit going on around each page of Rex's blog-- there are lots of links, images, and text extraneous to the body of the day's post. The information that I would like to collect from each page is the puzzle date, the body of the blog post (which also contains constructor, difficulty, and theme), and the link to the prior day's puzzle.</p>
<h3>BeautifulSoup</h3>
<p>In order to begin playing around, we can open the webpage using Python's urllib2 library, and convert the file to a <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> object, giving us a 'beautiful' (oh no), nested structure to work with.</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">urllib2</span>

<span class="n">test_url</span> <span class="o">=</span> <span class="s">&#39;http://rexwordpuzzle.blogspot.com/2014/09/resin-used-in-incense-tue-9-16-14-1990s.html&#39;</span>
<span class="n">web_page</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">test_url</span><span class="p">)</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">web_page</span><span class="p">)</span>
</pre></div>


<p>The BeautifulSoup object looks much like the HTML, but allows us to easily search through the webpage for specific tags in order to find what we want. For instance, the post date, which is stored in a line that looks like this:</p>
<div class="highlight"><pre><span class="nt">&lt;h2</span> <span class="na">class=</span><span class="s">&quot;date-header&quot;</span><span class="nt">&gt;</span>Tuesday, September 23, 2014<span class="nt">&lt;/h2&gt;</span>
</pre></div>


<p>can be found simply by saying:</p>
<div class="highlight"><pre><span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;h2&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span> <span class="s">&#39;date-header&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
</pre></div>


<p>This will return the string 'Tuesday, September 23, 2014'
Similarly, the entirety of the post body can be found starting with a line that looks like this:</p>
<div class="highlight"><pre><span class="o">&lt;/</span><span class="n">div</span> <span class="n">class</span><span class="o">=</span><span class="s">&quot;post-body&quot;</span> <span class="n">id</span><span class="o">=</span><span class="s">&quot;post-########&quot;</span><span class="o">&gt;</span>
</pre></div>


<p>After being turned into a BeautifulSoup object, each HTML tag is also an object with attributes (such as 'class_' as seen above) and methods; this makes finding pieces of the webpage fairly intuitive. </p>
<p>With this, we can now write a few lines of code to take what we want from Rex's blog. I am going to take the date, the entirety of the text in the post body (to be parsed through at a later time).</p>
<div class="highlight"><pre><span class="n">date</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;h2&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span> <span class="s">&#39;date-header&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
<span class="n">post_body</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">&quot;post-body&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
</pre></div>


<h3>Crawling Through Pages</h3>
<p>Rex's blog has around 3000 crossword puzzle pages, and we'd like to scrape data off of each of them. We can easily find what we want on each page, but now we need to write a little function to crawl through each page and pull out the above data. In order to do this, we need to be able to find the link to the prior post on each page. Unfortunately, Rex's link format has changed over his years of posting (as has his post-body format, which is why I took that all as one chunk for each page), so it's a bit difficult to just search by date for the link to the prior post. In fact, the link to each puzzle looks something like this: <a href="http://rexwordpuzzle.blogspot.com/2014/09/snowman-in-disneys-frozen-tue-9-23-14.html">http://rexwordpuzzle.blogspot.com/2014/09/snowman-in-disneys-frozen-tue-9-23-14.html</a>, with the date towards the end of the url. Thankfully, at the bottom of each page is a link titled "Older Post", which easily takes us where we want to go. Links can be found within a page's <code>&lt;a&gt;</code> tags, with the links as the 'href' attribute. The "Older Post" link has class_='blog-pager-older-link'), so we can find the link by</p>
<div class="highlight"><pre><span class="n">page_line</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;a&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">&#39;blog-pager-older-link&#39;</span><span class="p">)</span>
<span class="n">next_page</span> <span class="o">=</span> <span class="n">page_line</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;href&#39;</span><span class="p">)</span>
</pre></div>


<p>We now have all the information we need to crawl through Rex's blog, and the following functions will enable us to do so:</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">getData</span><span class="p">(</span><span class="n">soup</span><span class="p">):</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Given a page from Rex&#39;s blog, return the post date, body, and link to the prior post</span>
<span class="sd">&#39;&#39;&#39;</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;h2&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span> <span class="s">&#39;date-header&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="n">post_body</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">&quot;post-body&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="n">page_line</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;a&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">&#39;blog-pager-older-link&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">page_line</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">break</span>
    <span class="n">next_page</span> <span class="o">=</span> <span class="n">page_line</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;href&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">date</span><span class="p">,</span> <span class="n">post_body</span><span class="p">,</span> <span class="n">next_page</span>

<span class="k">def</span> <span class="nf">WriteErrors</span><span class="p">(</span><span class="n">errors</span><span class="p">):</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Write list to a file</span>
<span class="sd">&#39;&#39;&#39;</span>
  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;error_list&quot;</span><span class="p">,</span> <span class="s">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">errors</span><span class="p">:</span>
      <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">&#39;&amp;s</span><span class="se">\n</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">item</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">crawlPages</span><span class="p">(</span><span class="n">startPage</span><span class="p">):</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Given a starting page, crawl the blog until there is no longer a &quot;next page&quot; link. </span>
<span class="sd">Return a list of post dates and a list of post bodies, along with writing an error</span>
<span class="sd">log for all URLErrors. </span>
<span class="sd">&#39;&#39;&#39;</span>  
  <span class="n">dates</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">body</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">web_page</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">startPage</span><span class="p">)</span>
  <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">web_page</span><span class="p">)</span>
  <span class="n">b</span><span class="o">=</span><span class="mi">0</span>
  <span class="n">errorCount</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">while</span> <span class="n">page_line</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">date</span><span class="p">,</span> <span class="n">post_body</span><span class="p">,</span> <span class="n">next_page</span> <span class="o">=</span> <span class="n">getData</span><span class="p">(</span><span class="n">soup</span><span class="p">)</span>
    <span class="n">dates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">date</span><span class="p">)</span>
    <span class="n">body</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">post_body</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">next_page</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">next_page</span><span class="p">)</span>
      <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">next_page</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">URLError</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">error</span> <span class="o">=</span> <span class="s">&#39;Prior Date is&#39;</span> <span class="o">+</span> <span class="n">date</span> <span class="o">+</span> <span class="s">&#39;: URLError = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">reason</span><span class="p">)</span>
      <span class="k">print</span> <span class="n">error</span>
      <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
      <span class="n">errorCount</span><span class="o">+=</span><span class="mi">1</span>
    <span class="n">b</span><span class="o">+=</span><span class="mi">1</span>
  <span class="n">WriteErrors</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">dates</span><span class="p">,</span> <span class="n">body</span>
</pre></div>


<p>While crawling through Rex's blog, occasionally I would get this error:
"urllib2.HTTPError: HTTP Error 503: Service Unavailable"
which would cause my code to quit. The try/except syntax enables the code to keep running after it has encountered this error, and also allows me to create a log of which pages I missed. The crawlPages function then returns a list of all post dates and all post bodies(alternatively I could have stored each paired date and post in a nested list structure, which would probably have been better). </p>
<p>I would now like to write all of this to a csv file for later use. However, the aquired data is all in unicode, which cannot be written to a csv file. We need to encode our data as UTF-8, which can be done using the following function. It loops through a list and encodes each element in UTF-8 while ignoring characters that it cannot handle.</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">convert</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Encode input in UTF-8</span>
<span class="sd">&#39;&#39;&#39;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">convert</span><span class="p">(</span><span class="n">element</span><span class="p">)</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="nb">input</span><span class="p">]</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">unicode</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">&#39;utf-8&#39;</span><span class="p">,</span> <span class="s">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>


<p>After encoding everything, I created a pandas dataframe (I'll discuss pandas in my next post) out of my two lists in order to simply write to csv. </p>
<div class="highlight"><pre><span class="n">dates</span> <span class="o">=</span> <span class="n">convert</span><span class="p">(</span><span class="n">dates</span><span class="p">)</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">convert</span><span class="p">(</span><span class="n">body</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span><span class="p">[]</span>
<span class="n">df</span><span class="p">[</span><span class="s">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dates2</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">&#39;post&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">body2</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">&#39;/Users/Brian/Desktop/Crosswords/NYT_Xword_Data.csv&#39;</span><span class="p">)</span>
</pre></div>


<h3>Wrapping Up</h3>
<p>We have successfully crawled through Rex's blog and created a database to start playing around with. In my next post, I'll talk about parsing through all of the post-bodies in order to get out the real information that I was after!</p>
            </div>
            <!-- /.entry-content -->
        </article>
    </section>

        </div>
        <div class="col-sm-3 well well-sm" id="sidebar">

<aside>
    <section>
        <ul class="list-group list-group-flush">



                <li class="list-group-item"><a href="http://bcapozzi88.github.io/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
                    <ul class="list-group " id="tags">
                    </ul>
                </li>    
    <li class="list-group-item"><h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
      <ul class="list-group" id="links">
        <li class="list-group-item">
            <a href="http://www.linkedin.com/in/bcapozzi" target="_blank">
                LinkedIn
            </a>
        </li>
        <li class="list-group-item">
            <a href="http://scholar.google.com/citations?hl=en&user=c7drUDYAAAAJ" target="_blank">
                Google Scholar Profile
            </a>
        </li>
        <li class="list-group-item">
            <a href="http://www.columbia.edu/~lv2117" target="_blank">
                Research Group Page
            </a>
        </li>
        <li class="list-group-item">
            <a href="https://github.com/bcapozzi88" target="_blank">
                Github
            </a>
        </li>
      </ul>
    </li>

        </ul>
    </section>

</aside>        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2014 Brian Capozzi
            &middot; Powered by <a href="https://github.com/DandyDev/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="http://bcapozzi88.github.io/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="http://bcapozzi88.github.io/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="http://bcapozzi88.github.io/theme/js/respond.min.js"></script>

    <!-- Google Analytics -->
    <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-55245722-1']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    <!-- End Google Analytics Code -->
</body>
</html>